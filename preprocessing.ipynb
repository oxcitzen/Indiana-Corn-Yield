{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aggregration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather_data\\2003_april_sept.csv\n",
      "weather_data\\2003_oct.csv\n",
      "weather_data\\2004_april_sept.csv\n",
      "weather_data\\2004_oct.csv\n",
      "weather_data\\2005_april_sept.csv\n",
      "weather_data\\2005_oct.csv\n",
      "weather_data\\2006_april_sept.csv\n",
      "weather_data\\2006_oct.csv\n",
      "weather_data\\2007_april_sept.csv\n",
      "weather_data\\2007_oct.csv\n",
      "weather_data\\2008_april_sept.csv\n",
      "weather_data\\2008_oct.csv\n",
      "weather_data\\2009_april_sept.csv\n",
      "weather_data\\2009_oct.csv\n",
      "weather_data\\2010_april_sept.csv\n",
      "weather_data\\2010_oct.csv\n",
      "weather_data\\2011_april_sept.csv\n",
      "weather_data\\2011_oct.csv\n",
      "weather_data\\2012_april_sept.csv\n",
      "weather_data\\2012_oct.csv\n",
      "weather_data\\2013_april_sept.csv\n",
      "weather_data\\2013_oct.csv\n",
      "weather_data\\2014_april_sept.csv\n",
      "weather_data\\2014_oct.csv\n",
      "weather_data\\2015_april_sept.csv\n",
      "weather_data\\2015_oct.csv\n",
      "weather_data\\2016_april_sept.csv\n",
      "weather_data\\2016_oct.csv\n",
      "weather_data\\2017_april_sept.csv\n",
      "weather_data\\2017_oct.csv\n",
      "weather_data\\2018_apriL_sept.csv\n",
      "weather_data\\2018_oct.csv\n",
      "weather_data\\2019_april_sept.csv\n",
      "weather_data\\2019_oct.csv\n",
      "weather_data\\2020_april_sept.csv\n",
      "weather_data\\2020_oct.csv\n",
      "weather_data\\2021_april_sept.csv\n",
      "weather_data\\2021_oct.csv\n",
      "weather_data\\2022_april_sept.csv\n",
      "weather_data\\2022_oct.csv\n",
      "weather_data\\2023_april_sept.csv\n",
      "weather_data\\2023_oct.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder containing CSV files\n",
    "folder_path = 'weather_data'\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "data_frames = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        current_data = pd.read_csv(file_path)\n",
    "        \n",
    "        print(file_path)\n",
    "        #print(current_data.shape)\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        data_frames.append(current_data)\n",
    "\n",
    "# Concatenate all DataFrames in the list along the rows\n",
    "aggregate_data = pd.concat(data_frames, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58710, 146)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_data.shape   \n",
    "\n",
    "# 58710 rows and 146 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>AWND</th>\n",
       "      <th>AWND_ATTRIBUTES</th>\n",
       "      <th>CDSD</th>\n",
       "      <th>CDSD_ATTRIBUTES</th>\n",
       "      <th>...</th>\n",
       "      <th>WDF2</th>\n",
       "      <th>WDF2_ATTRIBUTES</th>\n",
       "      <th>WDF5</th>\n",
       "      <th>WDF5_ATTRIBUTES</th>\n",
       "      <th>WDMV</th>\n",
       "      <th>WDMV_ATTRIBUTES</th>\n",
       "      <th>WSF2</th>\n",
       "      <th>WSF2_ATTRIBUTES</th>\n",
       "      <th>WSF5</th>\n",
       "      <th>WSF5_ATTRIBUTES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USC00122184</td>\n",
       "      <td>DEPUTY 1 WNW, IN US</td>\n",
       "      <td>38.79970</td>\n",
       "      <td>-85.67240</td>\n",
       "      <td>193.5</td>\n",
       "      <td>2003-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00128442</td>\n",
       "      <td>STENDAL, IN US</td>\n",
       "      <td>38.26714</td>\n",
       "      <td>-87.14299</td>\n",
       "      <td>198.1</td>\n",
       "      <td>2003-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00126023</td>\n",
       "      <td>MUNCIE, IN US</td>\n",
       "      <td>40.18250</td>\n",
       "      <td>-85.34970</td>\n",
       "      <td>294.4</td>\n",
       "      <td>2003-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00125055</td>\n",
       "      <td>LIGONIER 2 S, IN US</td>\n",
       "      <td>41.43111</td>\n",
       "      <td>-85.58972</td>\n",
       "      <td>282.2</td>\n",
       "      <td>2003-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00124642</td>\n",
       "      <td>KNIGHTSTOWN 2 ENE, IN US</td>\n",
       "      <td>39.80750</td>\n",
       "      <td>-85.48770</td>\n",
       "      <td>303.9</td>\n",
       "      <td>2003-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION                      NAME  LATITUDE  LONGITUDE  ELEVATION  \\\n",
       "0  USC00122184       DEPUTY 1 WNW, IN US  38.79970  -85.67240      193.5   \n",
       "1  USC00128442            STENDAL, IN US  38.26714  -87.14299      198.1   \n",
       "2  USC00126023             MUNCIE, IN US  40.18250  -85.34970      294.4   \n",
       "3  USC00125055       LIGONIER 2 S, IN US  41.43111  -85.58972      282.2   \n",
       "4  USC00124642  KNIGHTSTOWN 2 ENE, IN US  39.80750  -85.48770      303.9   \n",
       "\n",
       "      DATE  AWND AWND_ATTRIBUTES  CDSD CDSD_ATTRIBUTES  ...  WDF2  \\\n",
       "0  2003-10   NaN             NaN   NaN             NaN  ...   NaN   \n",
       "1  2003-10   NaN             NaN   NaN             NaN  ...   NaN   \n",
       "2  2003-10   NaN             NaN   NaN             NaN  ...   NaN   \n",
       "3  2003-10   NaN             NaN   NaN             NaN  ...   NaN   \n",
       "4  2003-10   NaN             NaN   NaN             NaN  ...   NaN   \n",
       "\n",
       "  WDF2_ATTRIBUTES  WDF5 WDF5_ATTRIBUTES  WDMV WDMV_ATTRIBUTES  WSF2  \\\n",
       "0             NaN   NaN             NaN   NaN             NaN   NaN   \n",
       "1             NaN   NaN             NaN   NaN             NaN   NaN   \n",
       "2             NaN   NaN             NaN   NaN             NaN   NaN   \n",
       "3             NaN   NaN             NaN   NaN             NaN   NaN   \n",
       "4             NaN   NaN             NaN   NaN             NaN   NaN   \n",
       "\n",
       "  WSF2_ATTRIBUTES  WSF5 WSF5_ATTRIBUTES  \n",
       "0             NaN   NaN             NaN  \n",
       "1             NaN   NaN             NaN  \n",
       "2             NaN   NaN             NaN  \n",
       "3             NaN   NaN             NaN  \n",
       "4             NaN   NaN             NaN  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(967, 146)\n",
      "(497, 106)\n"
     ]
    }
   ],
   "source": [
    "first_csv = pd.read_csv(\"weather_data\\\\2003_oct.csv\")\n",
    "last_csv = pd.read_csv(\"weather_data\\\\2023_oct.csv\")\n",
    "\n",
    "print(first_csv.shape) # 146 columns\n",
    "print(last_csv.shape)  # 106 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns not in df2: {'LX06_ATTRIBUTES', 'HX04_ATTRIBUTES', 'HN04', 'LN05_ATTRIBUTES', 'TSUN_ATTRIBUTES', 'HN06_ATTRIBUTES', 'MN06_ATTRIBUTES', 'LX04', 'HX06', 'PSUN_ATTRIBUTES', 'HX04', 'PSUN', 'HN05', 'MN05_ATTRIBUTES', 'MX06', 'MN05', 'HX06_ATTRIBUTES', 'HN04_ATTRIBUTES', 'MX06_ATTRIBUTES', 'LX06', 'LN04', 'LN06_ATTRIBUTES', 'HN06', 'MX04', 'LX05_ATTRIBUTES', 'LX04_ATTRIBUTES', 'MN04_ATTRIBUTES', 'MX05', 'LN06', 'MN06', 'MX04_ATTRIBUTES', 'TSUN', 'HX05_ATTRIBUTES', 'HX05', 'LN04_ATTRIBUTES', 'LN05', 'HN05_ATTRIBUTES', 'MX05_ATTRIBUTES', 'MN04', 'LX05'}\n",
      "Columns not in df1: set()\n"
     ]
    }
   ],
   "source": [
    "# Find columns that exist in first_csv but not in last_csv\n",
    "columns_not_in_df2 = set(first_csv.columns) - set(last_csv.columns)\n",
    "\n",
    "# Find columns that exist in last_csv but not in first_csv\n",
    "columns_not_in_df1 = set(last_csv.columns) - set(first_csv.columns)\n",
    "\n",
    "print(f'Columns not in df2: {columns_not_in_df2}')\n",
    "print(f'Columns not in df1: {columns_not_in_df1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LX06_ATTRIBUTES\n",
      "HX04_ATTRIBUTES\n",
      "HN04\n",
      "LN05_ATTRIBUTES\n",
      "TSUN_ATTRIBUTES\n",
      "HN06_ATTRIBUTES\n",
      "MN06_ATTRIBUTES\n",
      "LX04\n",
      "HX06\n",
      "PSUN_ATTRIBUTES\n",
      "HX04\n",
      "PSUN\n",
      "HN05\n",
      "MN05_ATTRIBUTES\n",
      "MX06\n",
      "MN05\n",
      "HX06_ATTRIBUTES\n",
      "HN04_ATTRIBUTES\n",
      "MX06_ATTRIBUTES\n",
      "LX06\n",
      "LN04\n",
      "LN06_ATTRIBUTES\n",
      "HN06\n",
      "MX04\n",
      "LX05_ATTRIBUTES\n",
      "LX04_ATTRIBUTES\n",
      "MN04_ATTRIBUTES\n",
      "MX05\n",
      "LN06\n",
      "MN06\n",
      "MX04_ATTRIBUTES\n",
      "TSUN\n",
      "HX05_ATTRIBUTES\n",
      "HX05\n",
      "LN04_ATTRIBUTES\n",
      "LN05\n",
      "HN05_ATTRIBUTES\n",
      "MX05_ATTRIBUTES\n",
      "MN04\n",
      "LX05\n"
     ]
    }
   ],
   "source": [
    "for i in columns_not_in_df2:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns ending with \"_attributes\"\n",
    "attributes_columns = [col for col in aggregate_data.columns if col.endswith(\"_ATTRIBUTES\")]\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "df_attributes = aggregate_data[attributes_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58710, 70)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attributes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column \"AWND_ATTRIBUTES\" has 56954 NaN values.\n",
      "Column \"CDSD_ATTRIBUTES\" has 47278 NaN values.\n",
      "Column \"CLDD_ATTRIBUTES\" has 45323 NaN values.\n",
      "Column \"DP01_ATTRIBUTES\" has 3675 NaN values.\n",
      "Column \"DP10_ATTRIBUTES\" has 3675 NaN values.\n",
      "Column \"DSND_ATTRIBUTES\" has 40324 NaN values.\n",
      "Column \"DSNW_ATTRIBUTES\" has 34751 NaN values.\n",
      "Column \"DT00_ATTRIBUTES\" has 45275 NaN values.\n",
      "Column \"DT32_ATTRIBUTES\" has 45275 NaN values.\n",
      "Column \"DX32_ATTRIBUTES\" has 45160 NaN values.\n",
      "Column \"DX70_ATTRIBUTES\" has 45160 NaN values.\n",
      "Column \"DX90_ATTRIBUTES\" has 45160 NaN values.\n",
      "Column \"EMNT_ATTRIBUTES\" has 45275 NaN values.\n",
      "Column \"EMSD_ATTRIBUTES\" has 40324 NaN values.\n",
      "Column \"EMSN_ATTRIBUTES\" has 34751 NaN values.\n",
      "Column \"EMXP_ATTRIBUTES\" has 3675 NaN values.\n",
      "Column \"EMXT_ATTRIBUTES\" has 45160 NaN values.\n",
      "Column \"EVAP_ATTRIBUTES\" has 58103 NaN values.\n",
      "Column \"HDSD_ATTRIBUTES\" has 47072 NaN values.\n",
      "Column \"HN01_ATTRIBUTES\" has 57349 NaN values.\n",
      "Column \"HN02_ATTRIBUTES\" has 57520 NaN values.\n",
      "Column \"HN03_ATTRIBUTES\" has 58269 NaN values.\n",
      "Column \"HN04_ATTRIBUTES\" has 58511 NaN values.\n",
      "Column \"HN05_ATTRIBUTES\" has 58664 NaN values.\n",
      "Column \"HN06_ATTRIBUTES\" has 58665 NaN values.\n",
      "Column \"HTDD_ATTRIBUTES\" has 45323 NaN values.\n",
      "Column \"HX01_ATTRIBUTES\" has 57348 NaN values.\n",
      "Column \"HX02_ATTRIBUTES\" has 57519 NaN values.\n",
      "Column \"HX03_ATTRIBUTES\" has 58271 NaN values.\n",
      "Column \"HX04_ATTRIBUTES\" has 58513 NaN values.\n",
      "Column \"HX05_ATTRIBUTES\" has 58664 NaN values.\n",
      "Column \"HX06_ATTRIBUTES\" has 58664 NaN values.\n",
      "Column \"LN01_ATTRIBUTES\" has 57349 NaN values.\n",
      "Column \"LN02_ATTRIBUTES\" has 57520 NaN values.\n",
      "Column \"LN03_ATTRIBUTES\" has 58269 NaN values.\n",
      "Column \"LN04_ATTRIBUTES\" has 58511 NaN values.\n",
      "Column \"LN05_ATTRIBUTES\" has 58664 NaN values.\n",
      "Column \"LN06_ATTRIBUTES\" has 58665 NaN values.\n",
      "Column \"LX01_ATTRIBUTES\" has 57348 NaN values.\n",
      "Column \"LX02_ATTRIBUTES\" has 57519 NaN values.\n",
      "Column \"LX03_ATTRIBUTES\" has 58271 NaN values.\n",
      "Column \"LX04_ATTRIBUTES\" has 58513 NaN values.\n",
      "Column \"LX05_ATTRIBUTES\" has 58664 NaN values.\n",
      "Column \"LX06_ATTRIBUTES\" has 58664 NaN values.\n",
      "Column \"MN01_ATTRIBUTES\" has 57349 NaN values.\n",
      "Column \"MN02_ATTRIBUTES\" has 57520 NaN values.\n",
      "Column \"MN03_ATTRIBUTES\" has 58269 NaN values.\n",
      "Column \"MN04_ATTRIBUTES\" has 58511 NaN values.\n",
      "Column \"MN05_ATTRIBUTES\" has 58664 NaN values.\n",
      "Column \"MN06_ATTRIBUTES\" has 58665 NaN values.\n",
      "Column \"MNPN_ATTRIBUTES\" has 58214 NaN values.\n",
      "Column \"MX01_ATTRIBUTES\" has 57348 NaN values.\n",
      "Column \"MX02_ATTRIBUTES\" has 57519 NaN values.\n",
      "Column \"MX03_ATTRIBUTES\" has 58271 NaN values.\n",
      "Column \"MX04_ATTRIBUTES\" has 58513 NaN values.\n",
      "Column \"MX05_ATTRIBUTES\" has 58664 NaN values.\n",
      "Column \"MX06_ATTRIBUTES\" has 58664 NaN values.\n",
      "Column \"MXPN_ATTRIBUTES\" has 58215 NaN values.\n",
      "Column \"PRCP_ATTRIBUTES\" has 894 NaN values.\n",
      "Column \"PSUN_ATTRIBUTES\" has 58710 NaN values.\n",
      "Column \"SNOW_ATTRIBUTES\" has 34751 NaN values.\n",
      "Column \"TAVG_ATTRIBUTES\" has 45299 NaN values.\n",
      "Column \"TMAX_ATTRIBUTES\" has 45160 NaN values.\n",
      "Column \"TMIN_ATTRIBUTES\" has 45275 NaN values.\n",
      "Column \"TSUN_ATTRIBUTES\" has 58671 NaN values.\n",
      "Column \"WDF2_ATTRIBUTES\" has 56956 NaN values.\n",
      "Column \"WDF5_ATTRIBUTES\" has 56958 NaN values.\n",
      "Column \"WDMV_ATTRIBUTES\" has 58189 NaN values.\n",
      "Column \"WSF2_ATTRIBUTES\" has 56956 NaN values.\n",
      "Column \"WSF5_ATTRIBUTES\" has 56958 NaN values.\n"
     ]
    }
   ],
   "source": [
    "# Get the NaN counts for each column\n",
    "nan_counts = df_attributes.isna().sum()\n",
    "\n",
    "# Loop through the Series and print column names along with NaN counts\n",
    "for column, nan_count in nan_counts.items():\n",
    "    print(f'Column \"{column}\" has {nan_count} NaN values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AWND_ATTRIBUTES    56954\n",
       "CDSD_ATTRIBUTES    47278\n",
       "CLDD_ATTRIBUTES    45323\n",
       "DP01_ATTRIBUTES     3675\n",
       "DP10_ATTRIBUTES     3675\n",
       "                   ...  \n",
       "WDF2_ATTRIBUTES    56956\n",
       "WDF5_ATTRIBUTES    56958\n",
       "WDMV_ATTRIBUTES    58189\n",
       "WSF2_ATTRIBUTES    56956\n",
       "WSF5_ATTRIBUTES    56958\n",
       "Length: 70, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attributes.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Attributes\" Columns in GSOM Data\n",
    "\n",
    "Within the GSOM (Global Summary of the Month) data records, columns labeled with names ending in \"_attributes\" play a crucial role by furnishing additional metadata and insights related to specific climate or weather measurements. Each of these columns encapsulates a string of characters, representing diverse attributes associated with the primary measurement columns.\n",
    "\n",
    "However, it's noteworthy that a significant portion of values in these columns is populated with \"NaN,\" rendering them devoid of meaningful insights for our predictive analysis. The prevalence of missing values contributes to high dimensionality, hindering the interpretability of the analysis. In light of this, we have decided to drop these columns to streamline the model and enhance its simplicity. This strategic simplification aims to improve the model's performance and make it more efficient for our specific analytical objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_data_v2 = aggregate_data.drop(columns=attributes_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58710, 76)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_data_v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
